# 优化器
管理并更新模型中可学习参数的值，使得模型输出更接近真实标签
## 基本属性
* defaults: 优化器超参数
* state：参数的缓存，如momentum的缓存
* param_groups: 管理的参数组
* _step_count：记录更新次数，学习率调整中使用

## 基本方法：
* zero_grad()：清空所管理参数的梯度
* step（）：执行一步更新
* add_param_group()：添加参数组

      w2 = torch.randn((3,3),requires_grad=True)
      optimiter.add_param_group({"params":w2, 'lr':0.0001})

* state_dict()：获取优化器当前状态信息字典
* load_state_dict():加载状态信息字典

## class _LRScheduler
主要属性
* optimizer：关联的优化器
* last_epoch: 记录epoch数
* base_lrs:记录初始学习率

 
