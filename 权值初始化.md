### Xavier初始化(只适用于饱和函数)
方差一致性：保持数据尺度维持在恰当范围，通常方差为1
激活函数：饱和函数，如Sigmoid,Tanh

tanh_gain = nn.init.calculate_gain('tanh')
nn.init.xavier_uniform_(m.weight.data, gain=tanh_gain)



### kaiming初始化   
方差一致性：保持数据尺度维持在恰当范围，通常方差为1
激活函数：RELU及其变种

nn.init.kaiming_normal_(m.weight.data)

### nn.init.calculate_gain
功能：计算激活函数的方差变化尺度
主要参数：
* nonlinearity:激活函数名称
* param：激活函数的参数，如Leaky RELU的negative_shop

## 十种初始化方法
![image](https://github.com/tiancai134007/Pytorch-/blob/main/image/初始化方法.png)


