## 损失函数、代价函数与目标函数的区别
![image](https://github.com/tiancai134007/Pytorch-/blob/main/image/函数区别.png)

其中
* 损失函数计算的是单个样本的损失值
* 代价函数计算的是所有样本损失和的平均值
* 目标函数需要Regularization（正则项）

![image](https://github.com/tiancai134007/Pytorch-/blob/main/image/交叉熵.png)

## nn.CrossEntropyLoss
功能：nn.LogSoftmax()与nn.NLLLoss()结合，进行交叉熵计算
主要参数：
* weight：各类别的loss设置权值
* ignore_index:忽略某个类别
* reduction：计算模式，可为none/sum/mean
none-逐个元素计算
sum-所有元素求和，返回标量
mean-加权平均，返回标量

## nn.NLLLoss
功能：实现负对数似然函数中的负号功能
主要参数：
* weight：各类别的loss设置权值
* ignore_index:忽略某个类别
* reduction：计算模式，可为none/sum/mean
none-逐个元素计算
sum-所有元素求和，返回标量
mean-加权平均，返回标量

## nn.BCELoss
功能：二分类交叉熵
注意事项：输入值取值在[0,1]
主要参数：
* weight：各类别的loss设置权值
* ignore_index:忽略某个类别
* reduction：计算模式，可为none/sum/mean
none-逐个元素计算
sum-所有元素求和，返回标量
mean-加权平均，返回标量

## nn.BCEWithLogitsLoss
功能：结合Sigmoid与二分类交叉熵
注意事项：网络最后不加sigmoid函数
主要参数：
* pos_weight:正样本的权值
* weight：各类别的loss设置权值
* ignore_index:忽略某个类别
* reduction：计算模式，可为none/sum/mean
none-逐个元素计算
sum-所有元素求和，返回标量
mean-加权平均，返回标量
